# 어텐션의 목표

- 입력 임베딩 벡터를 **문맥을 고려한 V 벡터로 변환**하는 것이 핵심입니다.
- **Q와 K 벡터**를 사용하여 각 단어 간의 **어텐션 점수**를 계산하고, 이를 통해 **V 벡터를 업데이트**합니다.

# Q, K, V 벡터

- **Q와 K는 고정된 벡터**입니다. (즉, 주어진 입력 임베딩에서 선형 변환을 통해 Q와 K가 고정되고 업데이트되지 않습니다.)
- **V 벡터는 각 단어마다 문맥을 반영하여 한 번씩 업데이트**됩니다.

# 어텐션 과정 (예시: '나는 사과를 먹었다')

### 과정1: '나는'

- **"나는"**의 Q 벡터와 다른 단어들의 K 벡터를 내적하여 어텐션 점수를 계산하고, 이를 통해 **"나는"**의 V 벡터를 업데이트합니다.

### 과정2: '사과를'

- **"사과를"**의 Q 벡터와 다른 단어들의 K 벡터를 내적하여 어텐션 점수를 계산하고, 이를 통해 **"사과를"**의 V 벡터를 업데이트합니다.

### 과정3: '먹었다'

- **"먹었다"**의 Q 벡터와 다른 단어들의 K 벡터를 내적하여 어텐션 점수를 계산하고, 이를 통해 **"먹었다"**의 V 벡터를 업데이트합니다.

### 결론

- 어텐션 메커니즘에서 **V 벡터를 업데이트**하는 것은 각 단어가 문장 내 다른 단어들과 어떻게 연관되는지를 **문맥적으로 반영**하기 위함입니다.
- **Q와 K는 고정된 벡터**로 사용되며, **V 벡터는 문맥을 고려하여 각 단어마다 업데이트**됩니다.

# 계산 예시

### 1. Q, K, V 벡터 준비

우리는 각 단어에 대해 **Q**, **K**, **V** 벡터를 준비합니다. 여기서는 예시를 단순화하기 위해 작은 차원의 벡터를 사용하겠습니다.

- "나는" →
  - \( Q\_{\text{나는}} = [1, 0, 0] \),
  - \( K\_{\text{나는}} = [1, 1, 0] \),
  - \( V\_{\text{나는}} = [0.5, 0, 0] \)
- "사과를" →
  - \( Q\_{\text{사과를}} = [0, 1, 0] \),
  - \( K\_{\text{사과를}} = [1, 0, 1] \),
  - \( V\_{\text{사과를}} = [0, 0.5, 0] \)
- "먹었다" →
  - \( Q\_{\text{먹었다}} = [0, 0, 1] \),
  - \( K\_{\text{먹었다}} = [0, 1, 1] \),
  - \( V\_{\text{먹었다}} = [0, 0, 0.5] \)

### 2. 어텐션 점수 계산

각 단어마다 Q와 K의 내적을 통해 어텐션 점수를 계산합니다. 내적 값은 해당 단어가 다른 단어들과 얼마나 관련이 있는지를 나타냅니다.

예를 들어, **'나는'**의 Q 벡터와 다른 단어들의 K 벡터와 내적을 구해봅니다.

- **'나는'과 '나는'의 어텐션 점수**:
  \[
  \text{score}(\text{나는}, \text{나는}) = Q*{\text{나는}} \cdot K*{\text{나는}} = [1, 0, 0] \cdot [1, 1, 0] = 1
  \]

- **'나는'과 '사과를'의 어텐션 점수**:
  \[
  \text{score}(\text{나는}, \text{사과를}) = Q*{\text{나는}} \cdot K*{\text{사과를}} = [1, 0, 0] \cdot [1, 0, 1] = 1
  \]

- **'나는'과 '먹었다'의 어텐션 점수**:
  \[
  \text{score}(\text{나는}, \text{먹었다}) = Q*{\text{나는}} \cdot K*{\text{먹었다}} = [1, 0, 0] \cdot [0, 1, 1] = 0
  \]

### 3. 어텐션 점수에 Softmax 적용

Softmax를 통해 어텐션 점수를 확률로 변환합니다. Softmax는 점수의 상대적인 크기를 확률로 바꿔주며, 각 단어가 얼마나 중요한지를 나타냅니다.

- 어텐션 점수: \([1, 1, 0]\)
- Softmax 계산:
  \[
  \text{Softmax}(x_i) = \frac{e^{x_i}}{\sum e^{x_j}}
  \]
  이 점수들을 Softmax 함수에 적용해보면, 확률 분포가 나옵니다.

### 4. V 벡터 업데이트

어텐션 점수를 V 벡터에 가중치로 적용하여 새로운 V 벡터를 계산합니다.

가중치가 \( \text{Softmax}(1) \), \( \text{Softmax}(1) \), \( \text{Softmax}(0) \)라면, 각 단어의 V 벡터는 다음과 같이 가중합을 통해 업데이트됩니다.

예시에서는 **'나는'**의 새로운 V 벡터를 구하는 방법을 보면:
\[
V*{\text{나는}}^{\text{new}} = \text{Softmax}(1) \times V*{\text{나는}} + \text{Softmax}(1) \times V*{\text{사과를}} + \text{Softmax}(0) \times V*{\text{먹었다}}
\]

### 5. 최종 업데이트된 V 벡터

어텐션을 거친 후, 각 단어의 V 벡터는 문맥을 고려하여 업데이트된 값으로 변경됩니다. 이 새로운 벡터들은 문장을 더 정확하게 이해하는 데 사용됩니다.

### 전체 요약

- Q, K, V 벡터를 준비하고 각 단어에 대해 어텐션 점수를 계산합니다.
- 어텐션 점수는 Q와 K의 내적을 통해 구하고, 이를 **Softmax** 함수로 변환하여 확률화합니다.
- V 벡터는 이 확률에 따라 **가중합**하여 업데이트됩니다.
- 이 과정을 통해 각 단어는 **문맥을 반영한 새로운 V 벡터**를 얻게 되어, 문장의 의미를 더 잘 이해할 수 있습니다.
